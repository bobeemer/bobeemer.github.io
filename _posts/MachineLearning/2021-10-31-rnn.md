---

layout: post
title: RNN
category: 架构
tags: MachineLearning
keywords:  rnn

---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

## 简介

* TOC
{:toc}

传统的神经网络，以及CNN，它们存在的一个问题是，**采用固定的大小的输入并产生固定大小的输出**。而RNN呢？比如处理文本，其输入和输出的长度是可变的，比如，一对一，一对多，多对一，多对多。

![](/public/upload/machine/rnn_usage.png)

RNN是神经网络中的一种，它擅长对序列数据进行建模处理。序列数据有很多种形式。音频是一种自然的序列，你可以将音频频谱图分成块并将其馈入RNN。文本也是一种形式的序列，你可以将文本分成一系列字符或一系列单词。

1. 循环神经网络，引入状态变量来存储过去的信息，并用其与当期的输入共同决定当前的输出。 多层感知机 + 隐藏状态 = 循环神经网络
2. 应用到语言模型中时 ，循环神经网络根据当前词预测下一时刻词
3. 通常使用困惑度来衡量语言模型的好坏

RNN 输入和输出 根据目的而不同
1. 比如 根据一个字预测下一个字，输入就是一个字的特征向量（后续就是这个字的某个数字编号）
2. 给一个词 标记是名词还是动词
3. 语音处理。输入一个每帧的声音信号 的特征向量


## 为什么要发明循环神经网络

[史上最详细循环神经网络讲解（RNN/LSTM/GRU）](https://zhuanlan.zhihu.com/p/123211148)先来看一个NLP很常见的问题，命名实体识别，举个例子，现在有两句话：
1. 第一句话：I like eating apple！（我喜欢吃苹果！）
2. 第二句话：The Apple is a great company！（苹果真是一家很棒的公司！）

现在的任务是要给apple打Label，我们都知道第一个apple是一种水果，第二个apple是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把apple这个单词的特征向量输入到我们的模型中（如下图），在输出结果时，让我们的label里，正确的label概率最大，来训练模型，但我们的语料库中，有的apple的label是水果，有的label是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个label多一些，这样的模型对于我们来说完全没有作用。问题就出在了我们没有结合上下文去训练模型

![](/public/upload/machine/rnn_nn.jpg)

1. 「输入层」：X是一个向量，它表示「输入层」的值，并且**与隐藏层之间不是全连接**，而是按照时刻进行与隐藏层之间进行对齐连接。
2. 「隐藏层」：h是一个向量，它表示「隐藏层」的值（节点数与向量S的维度相同）；
3. 「输出层」：y是一个向量，它表示「输出层」的值；

RNN Cell（RNN 就是一个RNN Cell 的不断复制）：a typical vanilla RNN uses only 3 sets of weights to perform its calculations: $W_{xh}$,$W_{hh}$,$W_{hy}$。 We’ll also use two biases for our RNN: $b_h$,$b_y$。 

$$
h_t = tanh(W_{xh}x_t + W_{hh}h_{t-1} + b_h)
$$
$$
y_t = W_{hy}h_t + b_y
$$

## 经典RNN 结构

[如何深度理解RNN？——看图就好！](https://zhuanlan.zhihu.com/p/45289691)

```
rnn = RNN()
ff = FeedForwardNN()
hidden_state = [0.0,0.0,0.0,0.0]
for word in input:
    output , hidden_state = rnn(word, hidden_state)
    ...
prediction = ff(output)
```

[An Introduction to Recurrent Neural Networks for Beginners](https://victorzhou.com/blog/intro-to-rnns/) RNN 的前向 后向传播等，并给出了一个基于文本给出情感的例子，很仔细。PS： forward 和 backward 有点从左到右 和 从右向左的意思。 

```python
class RNN:
  # A Vanilla Recurrent Neural Network.
  def __init__(self, input_size, output_size, hidden_size=64):
    # Weights
    self.Whh = randn(hidden_size, hidden_size) / 1000
    self.Wxh = randn(hidden_size, input_size) / 1000
    self.Why = randn(output_size, hidden_size) / 1000

    # Biases
    self.bh = np.zeros((hidden_size, 1))
    self.by = np.zeros((output_size, 1))
  def forward(self, inputs):
    '''
    Perform a forward pass of the RNN using the given inputs.
    Returns the final output and hidden state.
    - inputs is an array of one-hot vectors with shape (input_size, 1).
    '''
    h = np.zeros((self.Whh.shape[0], 1))
    # Perform each step of the RNN
    for i, x in enumerate(inputs):
      h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)
    # Compute the output
    y = self.Why @ h + self.by
    return y, h
  def forward(self, inputs):
    '''
    Perform a forward pass of the RNN using the given inputs.
    Returns the final output and hidden state.
    - inputs is an array of one-hot vectors with shape (input_size, 1).
    '''
    h = np.zeros((self.Whh.shape[0], 1))

    self.last_inputs = inputs
    self.last_hs = { 0: h }
    # Perform each step of the RNN
    for i, x in enumerate(inputs):
      h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)
      self.last_hs[i + 1] = h
    # Compute the output
    y = self.Why @ h + self.by
    return y, h
```

##  LSTM



RNN网络对任意时刻的输入都是赋予相同权重计算，这样区分不出重点因素。可以进行一个短期的记忆，长期记忆的实现一般使用LSTM模型，当预测点与依赖的相关信息距离比较远的时候，就难以学到该相关信息。例如在句子“我是一名中国人，.......(省略数十字），我会说中文”，如果我们要预测末尾的“中文”两个字，我们需要上文的“中国人”，或者“中国”。

由于 RNN 自身的结构问题，在进行反向传播时，容易出现梯度消失或梯度爆炸。LSTM 网络在 RNN 结构的基础上进行了改进，通过精妙的门控制将短时记忆与长时记忆结合起来，一定程度上解决了梯度消失与梯度爆炸的问题。



## 注意力机制

对于一个由 n 个单词组成的句子来说，不同位置的单词，重要性是不一样的。因此，我们需要让模型“注意”到那些相对更加重要的单词，这种方式我们称之为注意力机制，也称作 Attention 机制。比如“我今天中午跑到了肯德基吃了仨汉堡”。这句话中，你一定对“我”、“肯德基”、“仨”、“汉堡”这几个词比较在意，不过，你是不是没注意到“跑”字？其实 Attention 机制要做的就是这件事：找到最重要的关键内容。它对网络中的输入（或者中间层）的不同位置，给予了不同的注意力或者权重，然后再通过学习，网络就可以逐渐知道哪些是重点，哪些是可以舍弃的内容了。

在普通的神经网络语言模型中，对于一个确定的单词，它的向量是固定的，但是现在不一样了，因为 Attention 机制，对于同一个单词，在不同语境下它的向量表达是不一样的。