---

layout: post
title: LLMOps
category: 技术
tags: MachineLearning
keywords: langchain

---

* TOC
{:toc}

## 前言（未完成）


钱，算力，数据哪个会成为大模型继续 scale 的瓶颈？总体来说最有可能成为瓶颈的是数据。在特定数据量下即使是无限的参数量都没法打败拥有更多数据量训练出来的有限参数量的模型。因为 retrieval 模式非常有效，所以大家自然会有想法说是不是不需要那么大的模型来记住各种知识点，而只需要一个拥有推理能力的小模型就可以？小模型可以在手机端，机器人设备上直接部署使用，想象空间还是非常大的。

我们的重点不是从头开始训练LLM，而是适应预训练的LLM用于下游任务。

![](/public/upload/machine/mlops_vs_llmops.jpg)

1. LangChain 的链式调用方法或者说编程语言 Python 不适合生产环境，真正工业级的应用需要有离线、近线几套系统配合供给，才能让在线系统效果出众、性能稳定。
2. 大模型通过提示词中信息的 Embedding 去检索外部记忆片段这种做法并不高明，充其量只是字面匹配的一个变种而已，存在非常明显的缺点。你无法找到主题最相近的文档，因为在一开始，你就把文档的语义切割了，更何况你所能使用的开源向量检索，根本没办法满足工业级的性能和数据量级要求。
3. 各类开源模型，比如 ChatGML 和 Llama 是无法直接拿来满足商业需求的。在大模型商业化的过程中，模型的领域定制是免不了的。

[LMOps 工具链与千帆大模型平台](https://mp.weixin.qq.com/s/lF0b_csan5aInfgBB2UT4Q) LLM 相关的所有操作可以白屏化进行。 